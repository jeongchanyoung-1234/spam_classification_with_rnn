{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_argparse():\n",
    "    p = {\n",
    "        'model_fn': './model.pth',\n",
    "        'batch_size': 256,\n",
    "        'topk': 1,\n",
    "        'gpu_id': -1,\n",
    "        'drop_rnn' : False,\n",
    "        'drop_cnn' : False,\n",
    "        'topk' : 1,\n",
    "    }\n",
    "    config = Namespace(**p)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def main(text, config):\n",
    "    saved_data = torch.load(\n",
    "        config.model_fn,\n",
    "        map_location='cpu' if config.gpu_id < 0 else 'cuda:{}'.format(config.gpu_id)\n",
    "    )\n",
    "\n",
    "    rnn_dict = saved_data['rnn']\n",
    "    cnn_dict = saved_data['cnn']\n",
    "    train_config = saved_data['config']\n",
    "    vocab = saved_data['vocab']\n",
    "    classes = saved_data['classes']\n",
    "\n",
    "    text_field = data.Field(batch_first=True)\n",
    "    label_field = data.Field(sequential=False,\n",
    "                             unk_token=None)\n",
    "\n",
    "    text_field.vocab = vocab\n",
    "    label_field.vocab = classes\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for t in text:\n",
    "        lines.append(t.strip().split(' ')[:train_config.max_length])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ensemble = []\n",
    "        if rnn_dict != None and not config.drop_rnn:\n",
    "            model = RNNclassifier(input_size=len(vocab),\n",
    "                                  emb_dim=train_config.emb_dim,\n",
    "                                  hidden_size=train_config.hidden_size,\n",
    "                                  n_layers=train_config.n_layers,\n",
    "                                  n_classes=len(classes),\n",
    "                                  dropout=train_config.dropout)\n",
    "            model.load_state_dict(rnn_dict)\n",
    "            ensemble.append(model)\n",
    "\n",
    "        if cnn_dict != None and not config.drop_cnn:\n",
    "            model = CNNclassifier(input_size=len(vocab),\n",
    "                                  emb_dim=train_config.emb_dim,\n",
    "                                  window_sizes=train_config.window_sizes,\n",
    "                                  n_filters=train_config.n_filters,\n",
    "                                  use_batchnorm=train_config.use_batchnorm,\n",
    "                                  dropout=train_config.dropout,\n",
    "                                  n_classes=len(classes))\n",
    "            model.load_state_dict(cnn_dict)\n",
    "            ensemble.append(model)\n",
    "\n",
    "        y_hats = []\n",
    "        for model in ensemble:\n",
    "            model.eval()\n",
    "\n",
    "            y_hat = []\n",
    "            for i in range(0, len(lines), config.batch_size):\n",
    "                x = text_field.numericalize(\n",
    "                    text_field.pad(lines[i:i + config.batch_size]),\n",
    "                    device = 'cpu' if config.gpu_id == -1 else 'cuda:{}'.format(config.gpu_id)\n",
    "                )\n",
    "\n",
    "                y_hat.append(model(x).cpu())\n",
    "                # y_hat = (bs, class)\n",
    "            y_hat = torch.cat(y_hat, dim=0)\n",
    "\n",
    "            y_hats.append(y_hat)\n",
    "        y_hats = torch.stack(y_hats, dim=0).exp()\n",
    "        # y_hats = (n_models, bs, class)\n",
    "        y_hats = torch.mean(y_hats, dim=0)\n",
    "        # y_hats = (bs, class)\n",
    "\n",
    "        probs, indices = torch.topk(y_hats, config.topk, dim=-1)\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            print('{}\\t{}\\n'.format(\n",
    "                    ' '.join(classes.itos[indices[i][j]] for j in range(config.topk)),\n",
    "                    ' '.join(lines[i])\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\tGood news for you! 50% discount\n",
      "\n",
      "ham\tWhat's up john? Long time no see.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ['Good news for you! 50% discount', \"What's up john? Long time no see.\"]\n",
    "\n",
    "config = define_argparse()\n",
    "main(text, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
